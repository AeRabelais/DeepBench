\title{DeepBench: A simulation package for physical benchmarking data}
\author{C. Xavier, Xavier's Institute for Talented Youngsters}
\date{May 2022}

\begin{document}

\maketitle

\section{Summary}
We introduce \texttt{DeepBench}, a python library  that generates simple simulated image data from first principles, such as basic geometric shapes and astronomical objects. 
These data are highly valuable for developing (calibration, testing, and benchmarking) statistical and machine learning models because they make it possible to connect the final data product to physically interpretable inputs. 
This software includes tools to curate and store the datasets to maximize reproducibility.
% We also present a trained ResNet50 model to illustrate the expected use of the software as a benchmarking tool for different architectures’ suitability to scientifically motivated problems. 

\section{Statement of Need}

One of the main motivations of this project was the production of a tool to softly introduce new practitioners of machine learning to simulation datasets, producing datasets that would be easy to integrate with out-of-the-box machine learning frameworks. 

\begin{enumerate}
    \item need replicability, reproducibility
    \item need simple objects -- simpler than most simulators
    \item need physically or geometrically useful objects
    \item needs good metadata tracking
    \item needs simple data that can be used for benchmarking and for education
\end{enumerate}

 \texttt{DeepBench} was designed and written with three key goals in mind: 1) ease of use, 2) diagnostics for model design, and 3) model benchmarking and testing. 

The astronomy community at large is experiencing a lack of benchmark datasets tailored toward the types of computer vision problems specific to astronomy. 

\section{Related Work}
Benchmarking and dataset generation is heavily used in the field of Machine Learning. 
MNIST, CIFAR, Imagenet
lenstronomy
astropy, galsim
Works that most closely related the work described here include \texttt{SHAPES} \cite{DBLP:journals/corr/WuTWSDH16} for its use of collections of geometric objects as a benchmark with varying levels of complexity, and  \texttt{deeplenstronomy} \cite{deeplenstronomy} for its packaging of astronomy simulation frameworks into tools with ease of use and reproducibility in mind. 


\section{Features}

\subsection{Simplicity}
To avoid needless complexity in execution and use of the program, the program was designed with the philosophy of being easy enough for someone with minimal programming experience to use. 

To avoid needless complexity in execution and use of the program, the program was designed with the philosophy of being easy enough for someone with minimal programming experience to use. 

\subsection{Reproducibility}

Including methods to catalog all produced images and provide a description of all generated objects included in the images. 
metadata tracking to help with benchmarking


\subsection{Diagnosis}
The software is also intended for use as a diagnostic tool, for help in identifying weaknesses during model developmenta. 
When working with a difficult problem, being able to incrementally scale back the difficulty (remove noise, decrease the number of classes, increase the class balance, etc.) can be a useful tool in finding the point of difficulty when training a new architecture. 
The design of \texttt{DeepBench} is such that configuration files can be generated with varying levels of complexity, making it possible to “roll back” the scale of a problem, such that possible areas of difficulty can be removed and added back in incrementally, allowing for problems to be solved one by one. 


\section{Modules}

\begin{figure}[h]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics{images/overview_diagram.png}}
\caption{An overview of the  \texttt{DeepBench} process. 
Dataset parameters, such as the type of objects in each image, and the associated qualities of each object, is passed to the catalog module by the user. 
These are collected and used by the Image module to call each individual object with their specified parameters, combined into one composite image, and noise, specified in the image parameters, is then applied before the image is saved. 
The parameters of each image is stored and saved as well.}
\label{fig:flow}
\end{center}
\vskip -0.2in
\end{figure}

 \begin{description}
    \item[Geometric Objects] Geometric objects are all generated by utilizing the library \texttt{matplotlib} \cite{Hunter:2007}, and are able to either be left as solid two-dimensional shapes or of an outline with a varying thickness. 
    Shapes include: Rectangles, n sided regular polygons, arcs. straight lines, ellipses, circles. 
    Shapes are limited to two-color rendering, such that all shapes are composed of 0 and 1 values within an array. 
    They can be combined in multiple ways using the "Image" module to produce composite images with both different geometric objects and astronomical objects. 
    
    \item[Physics Objects] The \emph{N-Body} object is currently the sole one-dimensional model available in the alpha release. 
    The N-Body model is output as a set of \texttt{NumPy} \cite{harris2020array} arrays containing coordinates representing the path of the points produced, along with the kinetic and potential energy produced over the specified duration.
    
    \item[Astronomical Objects] Astronomical objects offer simplified renderings of common profiles found in astronomical data sets. 
    Two-dimensional models are representations of astronomical objects commonly found in data sets used for galaxy morphology classification. 
    All objects also come with the option to append various levels of Gaussian and Poisson noise, and are output as \texttt{NumPy} arrays.  
    The \emph{Star} object is created using the Moffat distribution provided by the \texttt{AstroPy} \cite{astropy:2018} modeling library. 
    The \emph{(Elliptical) Galaxy} object is created using the Sérsic profile provided by the \texttt{AstroPy} modelling library. 
    The profile of the \emph{Spiral Galaxy} object is created by simulating the function used to produce a logarithmic spiral \cite{Ringermacher_2009}, along with reproducing the following relationship:

    \begin{equation}
    r(\phi) = A / log[B*tan(\phi/2N)]
\end{equation}

    \item[Image] The image module allows users to concatenate various shape or astronomical objects within a \texttt{matplotlib} meshgrid object in order to simulate the profiles and shape distributions commonly seen in images used in more complex astronomical data sets. 
    Three distinct image types are available - sky images, lensing images, and geometric images. 
    Sky images are composed of any combination of user-specified galaxy and star objects, while lensing images are randomized combinations of arc and star objects. 
    Lastly, geometric images are canvased assortments of any of the individual geometric shape objects available. 

    \item[Catalogue]
    The Catalogue module allows users to specify the size, contents, and output directory of a data set composed of \texttt{DeepBench}'s available image types or individual object images. 
    Catalogues can either be entirely randomized, with parameters of the included image being randomly chosen, or have parameters specified by the user at various levels of granularity. 
    The only required argument in the creation of Catalogue objects are the output directory and image type. 
    Within the Catalogue module also exists a Collection class, which concatenates various catalogues of varying image types into one data set. 
    Catalogues and collections can be output as a directory of.jpeg files, .npy, or .h5.

   
\end{description}


They can also have parameters that are either randomized or manually specified by the user via a configuration file.


\section{Example Usage}

\begin{description}
    \item[Geometric Shape Image] With the exception of the image dimensions, geometric images are also provided randomized default values for each of the available parameters in every available shape. The default image dimensions are defined as 256-by-256 pixels. Like astronomical objects, geometric shapes can be produced as individual objects or as a plot of concatenated shapes. Although each geometric object has distinct parameters necessary for the creation of a shape, the most commonly held configurable variables for each shape are the center, radius, and angle. See Figure ~\ref{fig:geom}.
    \item[Astronomical Object Images] All parameters of the astronomical objects are randomized at default with the exception of the image dimensions variable, which is set to a default value of 28-by-28 pixels. 
    The noise levels for the point-spread and Gaussian noise can also be specified for every astronomical image type.
    Configurable parameters for the Elliptical Galaxy object include the following: the image dimensions, center of the object, the amplitude, and the radius, along with an ellipse value and theta value. See Figure ~\ref{fig:ellipse}.
    Configurable parameters to produce the Spiral Galaxy object include the following: the image dimensions, the center of the object, the elliptic core size, the number of arms, the radius, and the amplitude. See Figure ~\ref{fig:spiral}.
    Configurable parameters for the Star object include: the image dimensions, noise, radius, center, and amplitude. See Figure ~\ref{fig:star}.
    Configurable parameters for the Lensing object are composed of the available variables used in each of its separate objects, namely the arc geometric object and star astronomical object. See Figure ~\ref{fig:lensing}.

\end{description}


\subsection{Simulation Examples}
put images and 1d data here


\subsection{Transfer Learning and Network Benchmarking}
Most benchmark datasets for computer vision are not designed with the flexibility to be used for astronomy research, as their focus tends to be replicating human vision and identification techniques. 
This leads to a lack of both accuracy baselines for networks that are applicable to astronomy problems, and a lack of pre-trained weights for large architectures that can be used in transfer and semi-supervised learning problems. 

\texttt{DeepBench} aims to help fill this need by producing datasets containing the distributions of images that more closely match the type of datasets used in more realistic studies, so that studies relying on pre-built architecture need not to retrain all weights from scratch. 
Training techniques that utilize this may see drastically decreased training run times, and provide out-of-the-box weights that can perform on related astronomy problems. 

This also allows for the distribution of Top N\% statistics for different networks and problem sets, in cases where comparison is desired. We hope that using this method of comparison allows for easier communication and comparison of results, encouraging collaboration and comparison between different research projects working on similar problems.

In the interest of providing an executed benchmark, multiple ResNet50 models \cite{DBLP:journals/corr/HeZRS15} was trained for three different classification tasks. The ResNet50 architecture was selected for both its high performance for image classification tasks, overall popularity, and its existing benchmarks on many other computer vision datasets. 

The architectures were trained using the \texttt{pyTorch} framework \cite{NEURIPS2019_9015}, using three different \texttt{DeepBench} variants; (1) A dataset containing "Sky" images, containing multiple structures per image, (2) A dataset containing geometric shapes, with multiple shapes per image, (3) Individual astronomical structures, with one star, galaxy, or spiral galaxy per image. 
Each dataset contained 10,000 total images, split 60/20/20 between training, validation, and testing distributions. 

All models were trained with a batch size of 64, learning rate of 0.524, weight decay rate of 0.00125. 

\begin{table}[]
\centering
\caption{Summary of results for the benchmark trained ResNet50 models. }
\label{tab:accuracies}
\begin{tabular}{c | c}
\hline
Dataset           & Accuracy \\
\hline
Sky Images        &  95.7     \\
Geometric Images  &  97.3     \\
Astronomy Objects &  97.1    \\
\hline
\end{tabular}
\end{table}



\section{Conclusion}

\section*{Acknowledgments}
